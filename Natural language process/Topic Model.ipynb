{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "#### she changlue\n",
    "20th April 2017\n",
    "\n",
    "This project is construct to handle documents topic classification.\n",
    "I use self designed algorithm to efficiently embedding the documents' topic vector and tokens' topic vector.It is emperiacally proved that this algorithm can classify the topic of different documents and tokens in a speed way.\n",
    "\n",
    "this notebook will process as follow:\n",
    "1. load library and raw corpus data\n",
    "2. cut the corpus in to a list format\n",
    "3. encode the tokens and corpus\n",
    "4. construct model and train\n",
    "5. use T-SNE to do tokens' and docs' cluster \n",
    "6. visualization\n",
    "7. save the outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)   load library and raw corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custormTokens.txt\n",
      "催收sample.csv\n",
      "马上消费金融_jiuhui.wu_2017-04-05.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import jieba.posseg as pseg\n",
    "import jieba\n",
    "import tensorflow as tf\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"corpus\"]).decode(\"utf8\"))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1.NBJ\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.593 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('corpus/custormTokens.txt')  \n",
    "rawdata = pd.read_csv('corpus/催收sample.csv', header=0,encoding='gbk' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corpus briefing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opr_rem</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>今天下午5点472</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t告知客户电话15226088432</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>说是叔侄关系  转告</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>客户承诺今天下午五点存入184</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    opr_rem  Unnamed: 1  Unnamed: 2  \\\n",
       "0                                 今天下午5点472           4         NaN   \n",
       "1                       \\t告知客户电话15226088432           3         NaN   \n",
       "2                               说是叔侄关系  转告            3         NaN   \n",
       "3                           客户承诺今天下午五点存入184           4         NaN   \n",
       "4  已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决           4         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4 Unnamed: 5  \n",
       "0         NaN         NaN        NaN  \n",
       "1         NaN         NaN        NaN  \n",
       "2         NaN         NaN        NaN  \n",
       "3         NaN         NaN        NaN  \n",
       "4         NaN         NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.944945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.091033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.160247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4\n",
       "count  999.000000         0.0         0.0    7.000000\n",
       "mean     3.944945         NaN         NaN    4.000000\n",
       "std      1.091033         NaN         NaN    2.160247\n",
       "min      1.000000         NaN         NaN    1.000000\n",
       "25%      4.000000         NaN         NaN         NaN\n",
       "50%      4.000000         NaN         NaN         NaN\n",
       "75%      4.000000         NaN         NaN         NaN\n",
       "max      7.000000         NaN         NaN    7.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) cut the corpus in to a list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenCorpus  = []#corpus list of cutted tokens\n",
    "rawSentences = []#raw text \n",
    "#documents    = list(rawdata[rawdata['消息目标']=='机器人']['消息内容'])#text which is send by custormers\n",
    "documents    = list(rawdata['opr_rem'])#text which is send by custormers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cstruct the corpus\n",
    "for sentence in documents:\n",
    "    sentence = sentence.replace('\\t','')\n",
    "    words = [pair.word for pair in pseg.lcut(sentence)]       \n",
    "    if len(words)>2:\n",
    "        tokenCorpus.append(words)\n",
    "        rawSentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今天下午', '5', '点', '472'],\n",
       " ['告知', '客户', '电话', '15226088432'],\n",
       " ['说', '是', '叔侄', '关系', ' ', ' ', '转告', ' ']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenCorpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天下午5点472',\n",
       " '告知客户电话15226088432',\n",
       " '说是叔侄关系  转告 ',\n",
       " '客户承诺今天下午五点存入184',\n",
       " '已提醒征信影响。已告知从今天凌晨开始又会多增加75元的滞纳金。客户敷衍明天去解决']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawSentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) encode the tokens and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HP_miniTokenFreq = 3 #minimal tokens frequency\n",
    "tokenCount = dict()  #token count\n",
    "token2code = dict()  #token to code\n",
    "code2token = ['inFreqTokens'] #code to token\n",
    "code       = 1       #code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transfer token into codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get token frequency\n",
    "for tokens in tokenCorpus:\n",
    "    for token in tokens:\n",
    "        tokenCount.setdefault(token,0)\n",
    "        tokenCount[token]+=1  \n",
    "#encode those tokens which have minumal frequency\n",
    "for token in tokenCount:\n",
    "    if tokenCount[token] > HP_miniTokenFreq:       \n",
    "        token2code[token] = code\n",
    "        code += 1\n",
    "        code2token.append(token)\n",
    "    else:\n",
    "        token2code[token] = 0\n",
    "#transfer the raw token corpus into encoded corpus\n",
    "codeCorpus = []\n",
    "for tokens in tokenCorpus:          \n",
    "    codeCorpus.append([token2code[token]for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) construct model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training documents num: 992\n",
      "the training tokens    num: 261\n"
     ]
    }
   ],
   "source": [
    "HP_topicNums = 8\n",
    "documNums = len(codeCorpus)\n",
    "tokenNums = len(code2token)\n",
    "print(\"the training documents num:\",documNums)\n",
    "print(\"the training tokens    num:\",tokenNums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dense list to sparse numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenDocMat = np.zeros(shape=(documNums,tokenNums),dtype=np.float32)\n",
    "for docIdx in range(documNums):\n",
    "    tokenDocMat[docIdx][codeCorpus[docIdx]]=1\n",
    "docTokenNum = tokenDocMat.sum(axis=1).reshape((-1,1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docIndxSpan = np.array(range(documNums),dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### construct the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#embedding initial\n",
    "docum2topicEmbed  = tf.Variable(tf.random_uniform([documNums,HP_topicNums], -1.0, 1.0))\n",
    "token2topicWeight = tf.Variable(tf.random_uniform([HP_topicNums,tokenNums], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#placeholder\n",
    "document_idx   = tf.placeholder(tf.int32, shape=[None])\n",
    "document_embed = tf.nn.embedding_lookup(docum2topicEmbed , document_idx) \n",
    "multiplier     = tf.placeholder(tf.float32, shape=[None,1])\n",
    "tokensInDoc    = tf.placeholder(tf.float32,shape=[None,tokenNums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#forward \n",
    "with tf.name_scope(\"TM\"):\n",
    "    documentembed_Sfmx     = tf.nn.softmax(document_embed)\n",
    "    token2topicWeight_Sfmx = tf.nn.softmax(token2topicWeight,dim=0)\n",
    "    tokensInDoc_pred       = tf.nn.softmax(tf.matmul(documentembed_Sfmx,token2topicWeight_Sfmx))*multiplier                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use least squre loss to train model\n",
    "with tf.name_scope(\"loss\"):   \n",
    "    loss = tf.reduce_mean(tf.square(tokensInDoc - tokensInDoc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer   = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial and save\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training the tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0315409\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "#start training\n",
    "n_epochs   = 1000\n",
    "batch_size = 100\n",
    "batch_num  = documNums//batch_size+1\n",
    "assess_size= 100\n",
    "with tf.Session() as sess:    \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batch_num):\n",
    "            #feed rawdata\n",
    "            document_idx_batch = docIndxSpan [batch*batch_size:(batch+1)*batch_size]\n",
    "            multiplier_batch   = docTokenNum [batch*batch_size:(batch+1)*batch_size]\n",
    "            tokensInDoc_batch  = tokenDocMat [batch*batch_size:(batch+1)*batch_size]\n",
    "             \n",
    "            #training\n",
    "            sess.run(training_op, feed_dict={document_idx : document_idx_batch,\n",
    "                                             multiplier   : multiplier_batch,\n",
    "                                             tokensInDoc  : tokensInDoc_batch})  \n",
    "        if epoch%100==0:\n",
    "            train_loss = loss.eval(feed_dict={document_idx : docIndxSpan [epoch*assess_size:(epoch+1)*assess_size],\n",
    "                                              multiplier   : docTokenNum [epoch*assess_size:(epoch+1)*assess_size],\n",
    "                                              tokensInDoc  : tokenDocMat [epoch*assess_size:(epoch+1)*assess_size]})\n",
    "            print(train_loss)\n",
    "    save_path = saver.save(sess,\"tfsave/topic_model.ckpt\")\n",
    "    # get embedding\n",
    "    documMat = documentembed_Sfmx.eval(feed_dict={document_idx : docIndxSpan})\n",
    "    tokenMat = token2topicWeight_Sfmx.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.99999994,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.00000012,  1.        ,\n",
       "         1.00000012,  1.        ,  1.00000012,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  0.99999994,  0.99999994,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  0.99999994,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999988,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.00000012,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  1.        ,  0.99999994,  0.99999988,  0.99999994,\n",
       "         1.00000012,  1.        ,  1.00000012,  1.        ,  1.        ,\n",
       "         0.99999994,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  0.99999988,  1.        ,\n",
       "         1.        ,  0.99999994,  1.00000012,  1.        ,  0.99999982,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  0.99999994,\n",
       "         0.99999994,  0.99999988,  1.00000012,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.00000012,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  0.99999988,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  0.99999988,  0.99999994,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  0.99999988,\n",
       "         0.99999988,  1.00000012,  1.        ,  0.99999988,  1.        ,\n",
       "         0.99999994,  1.00000012,  0.99999994,  1.00000012,  1.        ,\n",
       "         0.99999994,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.00000012,  1.        ,  1.        ,\n",
       "         0.99999988,  1.00000012,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         1.00000012,  1.00000012,  1.        ,  0.99999994,  1.00000012,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  0.99999994,\n",
       "         0.99999988,  0.99999988,  1.        ,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.00000012,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.00000012,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999994,  0.99999994,  1.        ,\n",
       "         0.99999988,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  0.99999994,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  0.99999994,  1.        ,\n",
       "         0.99999988,  1.00000012,  0.99999994,  0.99999994,  1.        ,\n",
       "         1.        ,  1.00000012,  1.00000012,  1.00000012,  1.        ,\n",
       "         1.        ,  1.        ,  1.00000012,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.00000012,\n",
       "         1.00000012,  1.        ,  0.99999988,  1.        ,  1.00000012,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  1.00000024,\n",
       "         0.99999994,  1.        ,  1.00000012,  1.        ,  0.99999994,\n",
       "         0.99999988,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.00000012,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  0.99999994,  0.99999994,  1.        ,  0.99999988,\n",
       "         1.00000012,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999994,  1.00000012,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.00000012,  1.        ,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.00000012,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.00000012,  0.99999988,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999988,  1.        ,  1.00000012,  1.        ,\n",
       "         0.99999994,  0.99999994,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999994,  0.99999994,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         0.99999988,  1.        ,  1.00000012,  0.99999988,  1.        ,\n",
       "         1.        ,  0.99999994,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.00000012,  1.00000012,  0.99999994,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.00000012,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         0.99999994,  0.99999994,  1.        ,  0.99999988,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  0.99999988,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999988,  0.99999994,  0.99999994,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.00000012,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.00000012,\n",
       "         1.        ,  0.99999988,  0.99999988,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  0.99999988,  0.99999988,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.        ,  1.00000012,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.00000012,  1.        ,\n",
       "         1.00000012,  1.        ,  0.99999994,  0.99999994,  0.99999994,\n",
       "         1.00000012,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  0.99999994,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  1.00000012,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999988,  1.00000012,  0.99999994,  1.        ,\n",
       "         0.99999994,  0.99999994,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  0.99999994,\n",
       "         1.        ,  0.99999988,  0.99999994,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999988,  0.99999994,  0.99999988,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  0.99999994,\n",
       "         1.        ,  1.        ,  1.00000012,  1.00000012,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.00000012,  1.        ,\n",
       "         0.99999988,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.00000012,  0.99999994,  1.00000012,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  1.        ,\n",
       "         0.99999994,  1.00000024,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999994,  1.00000012,  0.99999994,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  1.        ,\n",
       "         1.        ,  0.99999994,  0.99999982,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  0.99999988,\n",
       "         0.99999988,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         0.99999994,  1.        ], dtype=float32),\n",
       " array([ 1.00000012,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         0.99999988,  1.00000012,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999994,  1.00000012,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999988,  0.99999988,  1.        ,  0.99999988,\n",
       "         1.        ,  0.99999994,  0.99999994,  1.00000012,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999988,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  0.99999988,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  0.99999988,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999988,  1.00000012,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         0.99999994,  1.        ,  1.00000012,  0.99999988,  0.99999988,\n",
       "         1.        ,  0.99999994,  0.99999994,  0.99999988,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999988,  1.00000012,\n",
       "         0.99999994,  1.00000012,  1.        ,  1.        ,  0.99999982,\n",
       "         0.99999988,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  0.99999994,  1.00000012,  1.00000012,  1.        ,\n",
       "         0.99999988,  1.        ,  1.00000012,  1.        ,  1.        ,\n",
       "         1.        ,  1.00000012,  0.99999994,  0.99999988,  1.00000024,\n",
       "         0.99999994,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999988,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  0.99999994,  1.        ,  0.99999988,  1.        ,\n",
       "         1.00000012,  1.        ,  1.        ,  1.00000012,  1.00000012,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  0.99999988,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.99999988,\n",
       "         1.        ,  0.99999994,  1.        ,  1.        ,  0.99999994,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.99999994,  1.00000012,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  1.        ,\n",
       "         0.99999988,  0.99999988,  1.        ,  1.        ,  0.99999988,\n",
       "         1.00000012,  0.99999994,  1.        ,  1.00000012,  1.        ,\n",
       "         1.        ,  0.99999994,  0.99999994,  1.        ,  1.        ,\n",
       "         1.        ,  1.00000012,  1.        ,  1.        ,  1.        ,\n",
       "         0.99999982,  0.99999994,  0.99999994,  1.        ,  1.00000012,\n",
       "         1.00000012,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.00000012,  0.99999994,  0.99999994,  1.00000012,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.00000012,\n",
       "         1.        ,  1.        ,  0.99999994,  1.        ,  0.99999994,\n",
       "         0.99999988,  1.        ,  1.00000012,  1.        ,  1.00000012,\n",
       "         0.99999994,  1.        ,  1.        ,  0.99999994,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999988,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.99999994,  0.99999994,  1.        ,  1.        ], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documMat.sum(axis=1),tokenMat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show the rough topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outDF = []\n",
    "keyWords = []\n",
    "keySentences = []\n",
    "for idx in range(HP_topicNums):    \n",
    "    ords = np.argsort(-tokenMat[idx])[:10]\n",
    "    tmp = ['主题'+str(idx+1)]\n",
    "    tmp += [code2token[i]for i in ords]\n",
    "    keyWords+=tmp\n",
    "    ords = np.argsort(-documMat.T[idx])[:10]\n",
    "    tmp = ['--']\n",
    "    tmp +=[rawSentences[i]for i in ords]\n",
    "    keySentences+=tmp\n",
    "outDF = [keyWords,keySentences] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>主题1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>还清</td>\n",
       "      <td>客户姐姐，接听，说客户手机坏了，她是通过客户朋友联系到的客户，让告知客户朋友电话怎么都不愿意...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>承诺</td>\n",
       "      <td>15968747695销售来电，走对公，333.25梁丽花2016.12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>销售</td>\n",
       "      <td>其朋友接电，已告知留言转</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>后天</td>\n",
       "      <td>同事无法接听</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>被</td>\n",
       "      <td>不是赵宏国，是之前的同事，认识客户，联系不上。客户家庭情况不清楚。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>清楚</td>\n",
       "      <td>老二18388893497未接。大姐13320494866转达客回电。小文150878765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>都</td>\n",
       "      <td>工人太多不清楚，也没有听过这个名字</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>换卡</td>\n",
       "      <td>18314423858 销售来电，咨询提前还清，转接客服</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>手机</td>\n",
       "      <td>明天下午三点扣款</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>挂</td>\n",
       "      <td>客户卡里有钱，已告知系统统一代扣。金额：850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>主题2</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   主题1                                                 --\n",
       "1    还清  客户姐姐，接听，说客户手机坏了，她是通过客户朋友联系到的客户，让告知客户朋友电话怎么都不愿意...\n",
       "2    承诺             15968747695销售来电，走对公，333.25梁丽花2016.12.6\n",
       "3    销售                                       其朋友接电，已告知留言转\n",
       "4    后天                                             同事无法接听\n",
       "5     被                  不是赵宏国，是之前的同事，认识客户，联系不上。客户家庭情况不清楚。\n",
       "6    清楚  老二18388893497未接。大姐13320494866转达客回电。小文150878765...\n",
       "7     都                                  工人太多不清楚，也没有听过这个名字\n",
       "8    换卡                       18314423858 销售来电，咨询提前还清，转接客服\n",
       "9    手机                                          明天下午三点扣款 \n",
       "10    挂                            客户卡里有钱，已告知系统统一代扣。金额：850\n",
       "11  主题2                                                 --"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outDF).T.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)  use T-SNE to do tokens' and docs' cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
